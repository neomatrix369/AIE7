##### üèóÔ∏è Activity #1:

1. Explain the concept of object-oriented programming in simple terms to a complete beginner. 
    - Aspect Tested: 
    Factual accuracy / recall: it does not cite verifiable facts, tries to come up with things that can be perceived as distractor. If we were to compare the definition to that of a trusted resource on this topic, we can see a good difference.
    Style-guide adherence: the answer is meant for a beginner (in this case), and looking at the output it appears, it has not taken this into consideration, instead use technical terms mixed with its explanations 
    
2. Read the following paragraph and provide a concise summary of the key points‚Ä¶
    - Aspect Tested:
    Factual accuracy / recall: for the paragrah in the doc, the response appeared to be of lower quality compared to the original text
    Reasoning / chain-of-thought: The summarised text was quite compact but may have lost the important ideas from the original text

3. Write a short, imaginative story (100‚Äì150 words) about a robot finding friendship in an unexpected place.
    - Aspect Tested:
    Style-guide adherence: the generated text was within the 150 word count limit. From a creative and imaginative perspective it did a good job while staying within the limits specified
    Refusal & safety: the story didn't contain any unsafe, offensive, or inappropriate elements, hence can be considered safe. Although the LLMs refusal traits have not yet been tested with this.

4. If a store sells apples in packs of 4 and oranges in packs of 3, how many packs of each do I need to buy to get exactly 12 apples and 9 oranges?
    - Aspect Tested:
    Reasoning / chain-of-thought: it did break the problem down into its fundamental blocks first to then work towards the target values by building it up step by step, good reasoning was demonstrated. The answers were consistent even after repeating the queries a few times over.
    Factual accuracy / recall: 
    Prompt sensitivity: an example of a sensitive prompt where change in one or more facts can alter the answer quite a bit and tend to hallucinations or mistakes. The facts were preserved despite swapping the values in the prompt - usually LLMs can differ in answers between requests or when values are changed.

5. Rewrite the following paragraph in a professional, formal tone‚Ä¶
    - Aspect Tested:
    Style-guide adherence: it did follow the instruction(s) of converting the informal text generated by a search engine into a text with professional and formal tone
    Hallucination resistance: it didn't add any new ideas to the converted text which is a good display of resistance from hallucination(s)

Also see [Before-The-ai-engineer-challenge-av1ldonsw-manis-projects-6cdd8e65-vercel-app-2025-06-26-22_49_15.pdf](Before-The-ai-engineer-challenge-av1ldonsw-manis-projects-6cdd8e65-vercel-app-2025-06-26-22_49_15.pdf) document to see a few different tests performed while vibe checking the app before bringing any improvements to it and see [After-The-ai-engineer-challenge-neomatrix369-manis-projects-6cdd8e65-vercel-app-2025-06-27-00_02_03.pdf](After-The-ai-engineer-challenge-neomatrix369-manis-projects-6cdd8e65-vercel-app-2025-06-27-00_02_03.pdf).

Finally, improving the `developer prompt` a bit more and asking it to also provide references or sources from where it got the information from (wherever possible), see this [version](References-After-The-ai-engineer-challenge-neomatrix369-manis-projects-6cdd8e65-vercel-app-2025-06-27-00_02_03.pdf).

##### üßë‚Äçü§ù‚Äçüßë‚ùì Discussion Question #1:

What are some limitations of vibe checking as an evaluation tool?

Firstly its a very broad topic and cannot be easily determined if we rely on our human abilities and do not have hints or another human to discuss it with or get hints from.

It can be subjective and have no guard-rails or boundaries within which we need to adhere to, in order to come up with an output.

If we repeat this over and over different versions of the same application or across multiple applications we have built over a period of time, the style and content can vary quite a bit and then become inconsistent. May contain mistakes and may become non-comparable.

So in short we will have subjectivity and bias, resource intensive, and does not scale (which also points to consistency as a problem). Nuances are hard to notice, capture and compare, unless a standard has been created and adhered to. Although it can help fill gaps and also confirm (positively reinforce) things that an automated system would do. Could be used in addition to other methods, and keep the human-in-the-loop.