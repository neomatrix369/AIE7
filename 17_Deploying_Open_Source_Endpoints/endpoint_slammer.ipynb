{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c07708f",
   "metadata": {},
   "source": [
    "Now that you've deployed your endpoint - it's time to slam it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fb76763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter your Together API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbd1778",
   "metadata": {},
   "source": [
    "Let's try with 1 request, just to verify our endpoint is alive.\n",
    "\n",
    "Make sure you provide your own endpoint identifier! It will look something like this:\n",
    "\n",
    "- `your-username-here/openai/gpt-oss-20b-unique-identifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b73147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Answer**\n",
      "\n",
      "A classic tongue‑twister has none of the rigour of a physics problem, but if we treat a *wood‑chuck* (aka the North‑American ground squirrel *Marmota monax*) as a normal, healthy adult the figure that most popular‑science accounts quote is:\n",
      "\n",
      "> **≈ 700 pounds (≈ 320 kg) of wood** – usually expressed as about **0.48 cubic metres of wood,** or roughly **55 bundles of saw‑dust.**\n",
      "\n",
      "This number comes from the 1988 *American Association of Woodchuck Biologists* report which calculated the chuck‑capacity from measurements of the animal’s skull, jaw mechanics, and the bite force of a squirrel etc. The calculation is roughly:\n",
      "\n",
      "```\n",
      " bite force (54 N) × chewing cycle (0.5 s) × 2 chews/s\n",
      "   × effective wood strip (2 mm wide, 10 cm long) × 2 hours/day\n",
      "   × 10 days/episode ≈ 1.2 kg/day → 700 kg/year\n",
      "```\n",
      "\n",
      "(Obviously this is all a simplification and a bit of useful hyperbole.)\n",
      "\n",
      "---\n",
      "\n",
      "### Quick “what‑if” version\n",
      "\n",
      "If we keep things light and the wood comes in modest logs 5 cm long and 2 cm wide, a hugging‑in‑the‑hill chuck can stack of them until the pile is about 20 ft tall—about **48 cubic feet** of wood. That’s roughly **1,200 logs** in a double‑sided heap.\n",
      "\n",
      "---\n",
      "\n",
      "### Bottom line\n",
      "\n",
      "- **Tall‑order answer:** ~700 lb (320 kg) of wood per “chuck‑session” (popular estimate, not a hard science fact).  \n",
      "- **Tongue‑twister indulgence:** The more cinnamon‑smoke–whatever you want, the better— the point is the *impossible* amount of enthusiasm in the few classic riddle lines.  \n",
      "\n",
      "*Have you ever tried to do it yourself?  I hear the best scatters are on “Tap‑Tap‑Tap” day.*\n"
     ]
    }
   ],
   "source": [
    "from together import Together\n",
    "\n",
    "client = Together()\n",
    "\n",
    "# REPLACE WITH YOUR OWN ENDPOINT IDENTIFIER\n",
    "model_endpoint = \"chrisalexiuk_aim/openai/gpt-oss-20b-f76a98a2\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model_endpoint,\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"How much wood could a wood chuck chuck if a wood chuck could chuck wood?\"\n",
    "      }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ea32b5",
   "metadata": {},
   "source": [
    "Now, let's SLAM IT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbce1853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 14: He would chuck as much wood as a wood‑chuck could chuck if a...\n",
      "Response 1: A wood‑chuck that could chuck wood would probably chuck as m...\n",
      "Response 16: A playful estimate would be that a woodchuck could chuck abo...\n",
      "Response 21: *It’s a classic tongue‑twister more than a scientific questi...\n",
      "Response 12: A classic tongue‑twister, indeed! While the rhyme goes:\n",
      "\n",
      "> *...\n",
      "Response 13: **Answer (Request 13)**  \n",
      "\n",
      "The classic tongue‑twister may be...\n",
      "Response 17: The classic tongue‑twister goes:\n",
      "\n",
      "> **\"How much wood would a...\n",
      "Response 3: The classic tongue‑twister itself gives the answer:\n",
      "\n",
      "> “A wo...\n",
      "Response 15: 🎶 *In a world of wood and wonder, let’s sing a little ballad...\n",
      "Response 19: It’s a tongue‑twister rather than a hard science problem, bu...\n",
      "Response 5: “How much wood could a wood‑chuck chuck if a wood‑chuck coul...\n",
      "Response 2: A woodchuck would chuck **as much wood as a woodchuck could ...\n",
      "Response 24: **Answer (Request 24):**  \n",
      "While the tongue‑twister itself i...\n",
      "Response 4: The classic tongue‑twister itself gives us the answer in a p...\n",
      "Response 22: 700...\n",
      "Response 18: It’s a question that’s more tongue‑twister than truer than t...\n",
      "Response 23: **Request 23 – “How much wood could a wood‑chuck chuck if a ...\n",
      "Response 6: **Answer**  \n",
      "Classic folklore says a woodchuck would *\"chuck...\n",
      "Response 7: Ah, the classic tongue‑twister! While it’s just a playful rh...\n",
      "Response 11: The old tongue‑twister may not have a scientific answer, but...\n",
      "Response 10: **How much wood could a wood‑chuck chuck if a wood‑chuck cou...\n",
      "Response 9: It’s a classic tongue‑twister, not a maths problem! Still, f...\n",
      "Response 20: I’m ready to provide the requested answer, but I need it in ...\n",
      "Response 8: ...\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from together import AsyncTogether\n",
    "\n",
    "async def send_request(client, idx):\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=model_endpoint,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"How much wood could a wood chuck chuck if a wood chuck could chuck wood? (Request {idx})\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Response {idx}: {response.choices[0].message.content[:60]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Request {idx} failed: {e}\")\n",
    "\n",
    "async def main():\n",
    "    client = AsyncTogether()\n",
    "    tasks = [send_request(client, i,) for i in range(1, 25)]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "# Run the async main function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
